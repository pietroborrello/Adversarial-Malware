#! /usr/bin/env python3
# -*- coding: utf-8 -*-

# PLZ GOOGLE DON'T BAN ME, I'M ANALYZING MALWARES, BUT I KNOW WHAT I'M DOING

from keras.models import load_model
from keras.utils import plot_model
from keras import backend as K
from keras import metrics
import os
import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)
import tensorflow as tf
from sklearn.neighbors import NearestNeighbors
import os
import math
import random
from tqdm import tqdm
import argparse
import numpy as np
import lief
import warnings
# Set random seeds to improve reproducibility
np.random.seed(1234)
tf.set_random_seed(1234)
warnings.filterwarnings("ignore")  # Hide messy Numpy warnings


def bytez_to_numpy(bytez, maxlen, padding_char):
    b = np.ones((maxlen,), dtype=np.uint16) * padding_char
    bytez = np.frombuffer(bytez[:maxlen], dtype=np.uint8)
    b[:len(bytez)] = bytez
    return b


def numpy_to_bytez(np_bytez, padding_char):
    np_list = np_bytez.tolist()
    file_bytez = bytearray()
    for byte in np_list:
        try:
            file_bytez.append(byte)
        except ValueError:  # when meet padding
            return file_bytez
    return file_bytez


def get_file(filename, maxlen, padding_char):
    with open(filename, 'rb') as f:
        content = f.read()
    return bytez_to_numpy(content, maxlen, padding_char)


class MalConv:

    def __init__(self):
        self.input_dim = 257 # every byte plus a special padding symbol
        self.padding_char = 256 #
        self.model = load_model('malconv.h5') 
        self.maxlen = self.model.input_shape[1] # 1MB

        self.emb_layer = self.model.layers[1]
        self.emb_weight = self.emb_layer.get_weights()[0]
        self.neigh = NearestNeighbors(1)
        self.neigh.fit(self.emb_weight)

        self.get_emb = K.function([self.model.input] + [K.learning_phase()], [self.emb_layer.output])
    
    def predict(self, filename):
        np_file = get_file(filename, self.maxlen, self.padding_char)
        X = np.asarray([np_file], dtype=np.uint16)
        return self.model.predict(X)

    def _find_adversarial_embedding(self, filename, target_score = 0, max_iterations=1000, precision=0.00, header_only=False):
        inp = np.asarray([get_file(filename, self.maxlen, self.padding_char)], dtype=np.uint16)
        inp_embedding = np.squeeze(np.array(self.get_emb([inp, False])), 0)
        print('[+] Original Score: {}'.format(self.model.predict(inp)[0][0]))

        editable_indexes = self._find_editable_indexes(filename, self.maxlen, header_only=header_only)
        adversarial_embedding = inp_embedding.copy()
        k_target_score = K.variable([[target_score]])
        loss = K.binary_crossentropy(k_target_score, self.model.output)

        grads = K.gradients(loss, self.model.layers[1].output)[0]
        mask = np.zeros(self.model.layers[1].output.shape[1:])
        mask[editable_indexes] = 1
        grads *= K.constant(mask)

        get_loss_and_grad = K.function([self.model.layers[1].output], [loss, grads, self.model.output])
        original_score = None
        for i in range(max_iterations):
            loss_val, grad_val, score = get_loss_and_grad([adversarial_embedding])
            score = score[0][0]
            if i == 0: original_score = score
            if i % 10 == 0: print('[+] Iteration: {}\t-\tScore: {}\t-\tMax Grad: {}'.format(i, score, np.abs(grad_val).max()))

            # This is used to calculate the step-size.
            grad_absmax = np.abs(grad_val).max()
            if grad_absmax < 1e-10:
                print('[-] Iteration: {}\t-\tScore: {}\t-\tMax Grad: {}'.format(i, score, grad_absmax))

                # Worst possible scenario: never improved score and no gradient 
                # so random modification cannot be worse, and usually works
                if score == original_score:
                    grad_val = np.random.uniform(low=-1, high=1, size=grad_val.shape)
                    grad_val *= mask
                    grad_absmax = np.abs(grad_val).max()
                else:
                    break
            step_size = 1 / grad_absmax

            if abs(score - target_score) > precision:
                grad_val *= step_size
                adversarial_embedding -= grad_val
            else:
                break
        print('[*] Final Iteration: {}\t-\tScore: {}'.format(i, score))

        adversarial_input, score = self._emb_to_input(inp, inp_embedding[0], adversarial_embedding[0], self.neigh)
        return adversarial_input, score

    def adversarial_embedding(self, filename, target, header_only=False):
        with open(filename, 'rb') as f:
            original_content = f.read()

        adversarial_input, score = self._find_adversarial_embedding(
            filename, target_score=target, header_only=header_only)
        with open('{}.adversarial'.format(filename), 'wb') as f:
            f.write(numpy_to_bytez(adversarial_input[0], self.padding_char) + original_content[self.maxlen:])
            
        return score


    def _find_editable_indexes(self, filename, maxlen, header_only=False):
        with open(filename, 'rb') as f:
            file_content = f.read()
        
        editable_indexes = []
        e_lfanew_offset = 0x3c # offset to PE .exe header
        editable_indexes += list(range(0x2,e_lfanew_offset)) # first part of DOS header values, always editable
        e_lfanew = file_content[e_lfanew_offset]
        editable_indexes += list(range(e_lfanew_offset + 4, e_lfanew)) # second part of DOS header values, always editable
        
        if not header_only:
            binary = lief.parse(filename)
            for section in binary.sections:
                padding_offset = len(file_content[section.offset : section.offset + section.size].rstrip(b'\x00')) + 16 # leave 16 additional bytes for eventual last instruction
                if section.size - padding_offset > 0 and section.offset + section.size <= maxlen:
                    editable_indexes += list(range(section.offset + padding_offset, section.offset + section.size)) # include padding bytes between sections
        print('[*] Found {} editable bytes out of {} bytes: {}% of binary'.format(len(editable_indexes), len(file_content), len(editable_indexes)*100 / len(file_content)))
        return editable_indexes

    def _emb_to_input(self, org, inp_embedding, adversarial_embedding, neigh):
        print("Translating internal embedding representation to real bytes")
        out = org.copy()
        for idx in tqdm(range(org.shape[1])):
            if np.array_equal(inp_embedding[idx], adversarial_embedding[idx]):
                continue
            target = adversarial_embedding[idx].reshape(1, -1)
            best_idx = neigh.kneighbors(target, 1, False)[0][0]
            out[0][idx] = best_idx if best_idx != 256 else 0
        score = self.model.predict(out)[0][0]
        print('Actual Score:\t{}'.format(score))
        return out, score

def main():
    parser = argparse.ArgumentParser(description='MalConv adversarial examples')
    parser.add_argument('-t', '--target', type=int, default=0, help="target class (0: benign, 1: malign). default: 0")
    parser.add_argument('--header-only', action='store_true', help="Change only DOS header bytes")
    parser.add_argument('filename', type=str)

    args = parser.parse_args()

    model = MalConv()
    model.adversarial_embedding(args.filename, args.target, args.header_only)


if __name__ == "__main__":
    main()
